# .github/workflows/reusable-databricks.yml

name: Reusable Databricks CI/CD AWS Workflow

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      notebook_path:
        required: true
        type: string
      databricks_path:
        required: true
        type: string
      repo_path:
        required: false
        type: string
      repo_branch:
        required: false
        type: string
    secrets:
      DATABRICKS_HOST:
        required: true
      DATABRICKS_TOKEN:
        required: true

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install Databricks CLI
        run: pip install databricks-cli --upgrade  # Ensure the latest version


      - name: Configure Databricks CLI
        run: |
          mkdir -p ~/.databricks-cli  # Ensure the directory exists
          echo "[DEFAULT]" > ~/.databricks-cli/config
          echo "host = ${{ secrets.DATABRICKS_HOST }}" >> ~/.databricks-cli/config
          echo "token = ${{ secrets.DATABRICKS_TOKEN }}" >> ~/.databricks-cli/config
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

      - name: Sync latest Git changes in Databricks Repo
        if: ${{ inputs.environment == 'dev' && inputs.repo_path != '' && inputs.repo_branch != '' }}
        run: |
          echo "Pulling latest from branch ${{ inputs.repo_branch }} into repo at ${{ inputs.repo_path }}"
          databricks repos update --path "${{ inputs.repo_path }}" --branch "${{ inputs.repo_branch }}"
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

      - name: Ensure Databricks target folder exists
        if: ${{ inputs.environment == 'dev' }}
        run: |
          echo "Creating folder ${{ inputs.databricks_path }} if not exists"
          databricks workspace mkdirs "${{ inputs.databricks_path }}"
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

      - name: Upload notebooks to Databricks workspace folder (only for dev)
        if: ${{ inputs.environment == 'dev' }}
        run: |
          for notebook in $(find ${{ inputs.notebook_path }} -type f \( -iname "*.dbc" -o -iname "*.py" -o -iname "*.ipynb" \)); do
            notebook_name=$(basename "$notebook")
            target_path="${{ inputs.databricks_path }}/$notebook_name"
            echo "Uploading $notebook to $target_path"
            databricks workspace import "$notebook" "$target_path" --language PYTHON --overwrite
          done
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}


